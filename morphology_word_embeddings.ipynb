{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install gensim"
      ],
      "metadata": {
        "id": "9fc_-zkds7Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import pickle"
      ],
      "metadata": {
        "id": "5ow-xnMibvTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload xlsx file from your computer\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(filename, header=None)\n",
        "\n",
        "# Save as CSV (without headers, since func_morpheme_vector_pipeline expects no headers)\n",
        "csv_filename = filename.replace('.xlsx', '.csv')\n",
        "df.to_csv(csv_filename, index=False, header=False)\n",
        "\n",
        "print(f\"Converted {filename} to {csv_filename}\")\n",
        "print(f\"First few rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "tuBFo4N0sDCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pre-trained fastText (English)\n",
        "print(\"Downloading fastText embeddings...\")\n",
        "emb = api.load('fasttext-wiki-news-subwords-300')\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "1hNskvqWs4nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jxcYurSYoewx"
      },
      "outputs": [],
      "source": [
        "def func_morpheme_vector_pipeline(filename, myRs, emb):\n",
        "    \"\"\"\n",
        "    This function evaluates a morpheme transformation (like plural suffix)\n",
        "    using static word embeddings.\n",
        "    INPUT:\n",
        "        - filename: path to a .csv or .txt file with 2 columns (stem, affixed)\n",
        "        - myRs: a scaling factor (e.g., for regularization or dimension reduction)\n",
        "        - emb: a dictionary-like word embedding object with get_vector() method\n",
        "    OUTPUT:\n",
        "        - accuracy: proportion of correct top-1 predictions\n",
        "        - sums: total number of correct predictions\n",
        "    \"\"\"\n",
        "\n",
        "    numSamples = 100  # Number of random train/test splits\n",
        "    myAcc = np.zeros(numSamples)  # Stores 1 for correct, 0 for incorrect\n",
        "    myRanks = np.zeros(numSamples)  # Stores the rank of the correct word\n",
        "    predictedNeighborsAll = []  # Stores neighbors for analysis\n",
        "    sampleSize = 32  # Number of words per sample (1 test + 31 training)\n",
        "\n",
        "    # Read word pairs from file\n",
        "    wordList = pd.read_csv(filename, header=None)  # Expects 2 columns: [stem, affixed]\n",
        "\n",
        "    # Loop through samples\n",
        "    for s in range(numSamples):\n",
        "        idx = np.random.permutation(len(wordList))[:sampleSize]  # Randomly pick 32 rows\n",
        "        testIdx = idx[0]  # First word pair is for testing\n",
        "        trainIdx = idx[1:]  # Remaining 31 pairs for training\n",
        "\n",
        "        # Training words: stems and their inflected forms\n",
        "        stemTrain = wordList.iloc[trainIdx, 0].values\n",
        "        pluralTrain = wordList.iloc[trainIdx, 1].values\n",
        "\n",
        "        # Get embedding vectors\n",
        "        embStem = np.array([emb.get_vector(word.lower()) for word in stemTrain])\n",
        "        embPlural = np.array([emb.get_vector(word.lower()) for word in pluralTrain])\n",
        "\n",
        "        # Compute average transformation vector and apply transformation matrix\n",
        "        pluralVector = np.mean(embPlural - embStem, axis=0) * myRs\n",
        "\n",
        "        # Test word\n",
        "        testStem = wordList.iloc[testIdx, 0]\n",
        "        testPlural = wordList.iloc[testIdx, 1]\n",
        "\n",
        "        # Apply plural vector to test stem\n",
        "        testStemVec = emb.get_vector(testStem.lower())\n",
        "        predictedVec = testStemVec + pluralVector\n",
        "\n",
        "        # Predict nearest word from embedding space\n",
        "        neighbors_tuples = emb.most_similar(predictedVec, topn=10)  # Top-10 nearest neighbors\n",
        "        neighbors = [word for word, score in neighbors_tuples]  # Extract just the words\n",
        "\n",
        "        # Store neighbors and correct form\n",
        "        predictedNeighborsAll.append({\n",
        "            'testPlural': testPlural,\n",
        "            'neighbors': neighbors\n",
        "        })\n",
        "\n",
        "        # Check if the correct inflected form is in the top-10\n",
        "        neighbors_lower = [n.lower() for n in neighbors]\n",
        "        if testPlural.lower() in neighbors_lower:\n",
        "            rank = neighbors_lower.index(testPlural.lower()) + 1\n",
        "        else:\n",
        "            rank = 11  # If not found in top-10\n",
        "\n",
        "        myRanks[s] = rank\n",
        "        myAcc[s] = (rank == 1)  # Top-1 accuracy\n",
        "\n",
        "    # Calculate overall accuracy and correct prediction count\n",
        "    accuracy = np.sum(myAcc) / numSamples\n",
        "    sums = np.sum(myAcc)\n",
        "\n",
        "    # Save outputs to file\n",
        "    structName = f'Rs_{myRs:.1f}'\n",
        "    structName = structName.replace('.', '_')\n",
        "\n",
        "    baseName = filename.split('/')[-1].split('.')[0]\n",
        "\n",
        "    x = datetime.now()\n",
        "    myDate = x.strftime('%m%d')\n",
        "\n",
        "    saveDict = {\n",
        "        'myAcc': myAcc,\n",
        "        'myRanks': myRanks,\n",
        "        'predictedNeighborsAll': predictedNeighborsAll,\n",
        "        'accuracy': accuracy\n",
        "    }\n",
        "\n",
        "    saveName = f'morphoEmbVec{structName}_{baseName}_{myDate}.pkl'\n",
        "    with open(saveName, 'wb') as f:\n",
        "        pickle.dump(saveDict, f)\n",
        "\n",
        "    return accuracy, sums"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create func_emb_metrics.py\n",
        "def func_emb_metrics(xlsxFile):\n",
        "    \"\"\"\n",
        "    FUNC_EMB_METRICS calculates Top-1, Top-10, and Mean Rank from prediction results.\n",
        "\n",
        "    Input:\n",
        "        xlsxFile - Excel file containing 'Expected' column and 10 nearest neighbors\n",
        "\n",
        "    Output:\n",
        "        top1     - proportion of correct words ranked at position 1\n",
        "        top10    - proportion of correct words ranked in top 10\n",
        "        meanRank - average rank of correct words\n",
        "    \"\"\"\n",
        "\n",
        "    T = pd.read_excel(xlsxFile)\n",
        "\n",
        "    # Print columns to debug\n",
        "    print(f\"Columns in file: {T.columns.tolist()}\")\n",
        "\n",
        "    expected = T.iloc[:, 0]  # First column\n",
        "    myNeighbors = T.iloc[:, 1:].values  # all columns after the first\n",
        "\n",
        "    n = len(T)\n",
        "    top1Count = 0\n",
        "    top10Count = 0\n",
        "    ranks = np.zeros(n)\n",
        "\n",
        "    for i in range(n):\n",
        "        currentExpected = expected[i]\n",
        "        currentNeighbors = myNeighbors[i, :]\n",
        "\n",
        "        # Remove empty entries\n",
        "        currentNeighbors = [n for n in currentNeighbors if isinstance(n, str) and n != '']\n",
        "\n",
        "        # Find rank of expected form\n",
        "        matchIdx = []\n",
        "        for j, neighbor in enumerate(currentNeighbors):\n",
        "            if currentExpected.lower() == neighbor.lower():\n",
        "                matchIdx.append(j + 1)\n",
        "\n",
        "        if len(matchIdx) > 0:\n",
        "            if matchIdx[0] == 1:\n",
        "                top1Count = top1Count + 1\n",
        "            top10Count = top10Count + 1\n",
        "            ranks[i] = matchIdx[0]\n",
        "        else:\n",
        "            ranks[i] = np.nan  # mark as not found\n",
        "\n",
        "    # Compute metrics\n",
        "    top1Acc = top1Count / n\n",
        "    top10Acc = top10Count / n\n",
        "    meanRank = np.nanmean(ranks)\n",
        "\n",
        "    return top1Acc, top10Acc, meanRank"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m8vTP09y0dJ",
        "outputId": "855c8953-ac3d-4589-de01-c7e207b1589b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing func_emb_metrics.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute embedding metrics\n",
        "# This script processes the output from the morpheme vector pipeline:\n",
        "# 1) extract the predicted neighbours\n",
        "# 2) saves as an excel file\n",
        "# 3) evaluates neighbors using the func_emb_metrics function\n",
        "\n",
        "files = glob.glob('morphoEmbVec*.pkl')\n",
        "fileName = files[0]  # CHOOSE WHICH ONE YOU WANT TO EVLUATE\n",
        "print(f\"Processing: {fileName}\")\n",
        "\n",
        "with open(fileName, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "predictedNeighborsAll = data['predictedNeighborsAll']\n",
        "\n",
        "n = len(predictedNeighborsAll)\n",
        "expectedForms = []\n",
        "neighborsTop10 = []\n",
        "\n",
        "for i in range(n):\n",
        "    expectedForms.append(predictedNeighborsAll[i]['testPlural'])\n",
        "    theseNeighbors = predictedNeighborsAll[i]['neighbors']\n",
        "    row = []\n",
        "    for j in range(10):\n",
        "        if j < len(theseNeighbors):\n",
        "            row.append(theseNeighbors[j])\n",
        "        else:\n",
        "            row.append('')\n",
        "    neighborsTop10.append(row)\n",
        "\n",
        "neighborHeaders = [f'Neighbor_{x+1}' for x in range(10)]\n",
        "\n",
        "# Create table\n",
        "data_dict = {'Expected': expectedForms}\n",
        "for i, header in enumerate(neighborHeaders):\n",
        "    data_dict[header] = [row[i] for row in neighborsTop10]\n",
        "\n",
        "T = pd.DataFrame(data_dict)\n",
        "\n",
        "# Save as excel\n",
        "baseName = fileName.replace('morphoEmbVec', '').replace('.pkl', '')\n",
        "tableName = f'predNeighbors{baseName}.xlsx'\n",
        "print(f\"Saving table: {tableName}\")\n",
        "T.to_excel(tableName, index=False)\n",
        "\n",
        "# Call the metrics function (Turkish as an example)\n",
        "t1_tr, t10_tr, rank_tr = func_emb_metrics(tableName)\n",
        "print(f'Turkish Top-1: {t1_tr*100:.2f}%, Top-10: {t10_tr*100:.2f}%, Mean Rank: {rank_tr:.2f}')"
      ],
      "metadata": {
        "id": "7z6sgKfQb4To"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}