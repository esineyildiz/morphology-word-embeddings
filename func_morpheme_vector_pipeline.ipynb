{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install gensim"
      ],
      "metadata": {
        "id": "9fc_-zkds7Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "Khv2VsX-0_eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload xlsx file from your computer\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(filename, header=None)\n",
        "\n",
        "# Save as CSV (without headers, since func_morpheme_vector_pipeline expects no headers)\n",
        "csv_filename = filename.replace('.xlsx', '.csv')\n",
        "df.to_csv(csv_filename, index=False, header=False)\n",
        "\n",
        "print(f\"Converted {filename} to {csv_filename}\")\n",
        "print(f\"First few rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "tuBFo4N0sDCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pre-trained fastText (English)\n",
        "print(\"Downloading fastText embeddings...\")\n",
        "emb = api.load('fasttext-wiki-news-subwords-300')\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "1hNskvqWs4nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jxcYurSYoewx"
      },
      "outputs": [],
      "source": [
        "\n",
        "def func_morpheme_vector_pipeline(filename, myRs, emb):\n",
        "    \"\"\"\n",
        "    This function evaluates a morpheme transformation (like plural suffix)\n",
        "    using static word embeddings.\n",
        "    INPUT:\n",
        "        - filename: path to a .csv or .txt file with 2 columns (stem, affixed)\n",
        "        - myRs: a scaling factor (e.g., for regularization or dimension reduction)\n",
        "        - emb: a dictionary-like word embedding object with get_vector() method\n",
        "    OUTPUT:\n",
        "        - accuracy: proportion of correct top-1 predictions\n",
        "        - sums: total number of correct predictions\n",
        "    \"\"\"\n",
        "\n",
        "    numSamples = 100  # Number of random train/test splits\n",
        "    myAcc = np.zeros(numSamples)  # Stores 1 for correct, 0 for incorrect\n",
        "    myRanks = np.zeros(numSamples)  # Stores the rank of the correct word\n",
        "    predictedNeighborsAll = []  # Stores neighbors for analysis\n",
        "    sampleSize = 32  # Number of words per sample (1 test + 31 training)\n",
        "\n",
        "    # Read word pairs from file\n",
        "    wordList = pd.read_csv(filename, header=None)  # Expects 2 columns: [stem, affixed]\n",
        "\n",
        "    # Loop through samples\n",
        "    for s in range(numSamples):\n",
        "        idx = np.random.permutation(len(wordList))[:sampleSize]  # Randomly pick 32 rows\n",
        "        testIdx = idx[0]  # First word pair is for testing\n",
        "        trainIdx = idx[1:]  # Remaining 31 pairs for training\n",
        "\n",
        "        # Training words: stems and their inflected forms\n",
        "        stemTrain = wordList.iloc[trainIdx, 0].values\n",
        "        pluralTrain = wordList.iloc[trainIdx, 1].values\n",
        "\n",
        "        # Get embedding vectors\n",
        "        embStem = np.array([emb.get_vector(word.lower()) for word in stemTrain])\n",
        "        embPlural = np.array([emb.get_vector(word.lower()) for word in pluralTrain])\n",
        "\n",
        "        # Compute average transformation vector and apply transformation matrix\n",
        "        pluralVector = np.mean(embPlural - embStem, axis=0) * myRs\n",
        "\n",
        "        # Test word\n",
        "        testStem = wordList.iloc[testIdx, 0]\n",
        "        testPlural = wordList.iloc[testIdx, 1]\n",
        "\n",
        "        # Apply plural vector to test stem\n",
        "        testStemVec = emb.get_vector(testStem.lower())\n",
        "        predictedVec = testStemVec + pluralVector\n",
        "\n",
        "        # Predict nearest word from embedding space\n",
        "        neighbors_tuples = emb.most_similar(predictedVec, topn=10)  # Top-10 nearest neighbors\n",
        "        neighbors = [word for word, score in neighbors_tuples]  # Extract just the words\n",
        "\n",
        "        # Store neighbors and correct form\n",
        "        predictedNeighborsAll.append({\n",
        "            'testPlural': testPlural,\n",
        "            'neighbors': neighbors\n",
        "        })\n",
        "\n",
        "        # Check if the correct inflected form is in the top-10\n",
        "        neighbors_lower = [n.lower() for n in neighbors]\n",
        "        if testPlural.lower() in neighbors_lower:\n",
        "            rank = neighbors_lower.index(testPlural.lower()) + 1\n",
        "        else:\n",
        "            rank = 11  # If not found in top-10\n",
        "\n",
        "        myRanks[s] = rank\n",
        "        myAcc[s] = (rank == 1)  # Top-1 accuracy\n",
        "\n",
        "    # Calculate overall accuracy and correct prediction count\n",
        "    accuracy = np.sum(myAcc) / numSamples\n",
        "    sums = np.sum(myAcc)\n",
        "\n",
        "    # Save outputs to file\n",
        "    structName = f'Rs_{myRs:.1f}'\n",
        "    structName = structName.replace('.', '_')\n",
        "\n",
        "    baseName = filename.split('/')[-1].split('.')[0]\n",
        "\n",
        "    x = datetime.now()\n",
        "    myDate = x.strftime('%m%d')\n",
        "\n",
        "    saveDict = {\n",
        "        'myAcc': myAcc,\n",
        "        'myRanks': myRanks,\n",
        "        'predictedNeighborsAll': predictedNeighborsAll,\n",
        "        'accuracy': accuracy\n",
        "    }\n",
        "\n",
        "    saveName = f'morphoEmbVec{structName}_{baseName}_{myDate}.pkl'\n",
        "    with open(saveName, 'wb') as f:\n",
        "        pickle.dump(saveDict, f)\n",
        "\n",
        "    return accuracy, sums"
      ]
    }
  ]
}